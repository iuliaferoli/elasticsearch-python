{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "from getpass import getpass  \n",
    "from elasticsearch import Elasticsearch, helpers \n",
    "from elasticsearch.client import MlClient\n",
    "from langchain_community.vectorstores.elasticsearch import ElasticsearchStore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install --upgrade --quiet  elasticsearch langchain-openai tiktoken langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt the user to enter their Elastic Cloud ID and API Key securely\n",
    "ELASTIC_CLOUD_ID = getpass(\"Elastic Cloud ID: \")\n",
    "ELASTIC_API_KEY = getpass(\"Elastic API Key: \")\n",
    "\n",
    "# Create an Elasticsearch client using the provided credentials\n",
    "es = Elasticsearch(\n",
    "    cloud_id=ELASTIC_CLOUD_ID,  # cloud id can be found under deployment management\n",
    "    api_key=ELASTIC_API_KEY, # your username and password for connecting to elastic, found under Deplouments - Security\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"collection.tsv\", delimiter=\"\t\", header=None, names=[\"docid\", \"body\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docid</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>The presence of communication amid scientific ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>The Manhattan Project and its atomic bomb help...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Essay on The Manhattan Project - The Manhattan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>The Manhattan Project was the name for a proje...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>versions of each volume as well as complementa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   docid                                               body\n",
       "0      0  The presence of communication amid scientific ...\n",
       "1      1  The Manhattan Project and its atomic bomb help...\n",
       "2      2  Essay on The Manhattan Project - The Manhattan...\n",
       "3      3  The Manhattan Project was the name for a proje...\n",
       "4      4  versions of each volume as well as complementa..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = pd.read_csv(\"queries/queries.eval.tsv\", delimiter=\"\t\", header=None, names=[\"docid\", \"body\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "ELASTIC_CLOUD_ID = getpass(\"Elastic Cloud ID: \")\n",
    "ELASTIC_API_KEY = getpass(\"Elastic API Key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = \"hp\"\n",
    "model_id = \"sentence-transformers__msmarco-minilm-l-12-v3\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Three options:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# + generating embeddings within Elatic w/ inference runs\n",
    "db = ElasticsearchStore(\n",
    "    es_cloud_id=ELASTIC_CLOUD_ID,\n",
    "    es_api_key=ELASTIC_API_KEY,\n",
    "    index_name=index_name,\n",
    "    \n",
    "    query_field=\"text_field\",\n",
    "    vector_query_field=\"vector_query_field.predicted_value\",\n",
    "    strategy=ElasticsearchStore.ApproxRetrievalStrategy(\n",
    "            query_model_id=model_id\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# with external embeddings\n",
    "db = ElasticsearchStore(\n",
    "    es_cloud_id=ELASTIC_CLOUD_ID,\n",
    "    es_api_key=ELASTIC_API_KEY,\n",
    "    index_name=index_name,\n",
    "\n",
    "    embeddings = embeddings,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with ELSER\n",
    "db = ElasticsearchStore(\n",
    "    es_cloud_id=ELASTIC_CLOUD_ID,\n",
    "    es_api_key=ELASTIC_API_KEY,\n",
    "    index_name=index_name,\n",
    "    \n",
    "    strategy=ElasticsearchStore.SparseVectorRetrievalStrategy(),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with no embeddings\n",
    "db = ElasticsearchStore(\n",
    "    es_cloud_id=ELASTIC_CLOUD_ID,\n",
    "    es_api_key=ELASTIC_API_KEY,\n",
    "    index_name=index_name,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You must provide an embedding function or a query_model_id to perform a similarity search.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m docs \u001b[39m=\u001b[39m db\u001b[39m.\u001b[39;49m_search( query \u001b[39m=\u001b[39;49m {\u001b[39m\"\u001b[39;49m\u001b[39mmatch\u001b[39;49m\u001b[39m\"\u001b[39;49m: {\u001b[39m\"\u001b[39;49m\u001b[39mHouse\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39mGryffindor\u001b[39;49m\u001b[39m\"\u001b[39;49m}})\n",
      "File \u001b[0;32m~/python/cheat sheet/elasticsearch-python/.venv/lib/python3.11/site-packages/langchain_community/vectorstores/elasticsearch.py:798\u001b[0m, in \u001b[0;36mElasticsearchStore._search\u001b[0;34m(self, query, k, query_vector, fetch_k, fields, filter, custom_query, doc_builder, **kwargs)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding \u001b[39mand\u001b[39;00m query \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    796\u001b[0m     query_vector \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding\u001b[39m.\u001b[39membed_query(query)\n\u001b[0;32m--> 798\u001b[0m query_body \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstrategy\u001b[39m.\u001b[39;49mquery(\n\u001b[1;32m    799\u001b[0m     query_vector\u001b[39m=\u001b[39;49mquery_vector,\n\u001b[1;32m    800\u001b[0m     query\u001b[39m=\u001b[39;49mquery,\n\u001b[1;32m    801\u001b[0m     k\u001b[39m=\u001b[39;49mk,\n\u001b[1;32m    802\u001b[0m     fetch_k\u001b[39m=\u001b[39;49mfetch_k,\n\u001b[1;32m    803\u001b[0m     vector_query_field\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvector_query_field,\n\u001b[1;32m    804\u001b[0m     text_field\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mquery_field,\n\u001b[1;32m    805\u001b[0m     \u001b[39mfilter\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mfilter\u001b[39;49m \u001b[39mor\u001b[39;49;00m [],\n\u001b[1;32m    806\u001b[0m     similarity\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdistance_strategy,\n\u001b[1;32m    807\u001b[0m )\n\u001b[1;32m    809\u001b[0m logger\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mQuery body: \u001b[39m\u001b[39m{\u001b[39;00mquery_body\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    811\u001b[0m \u001b[39mif\u001b[39;00m custom_query \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/python/cheat sheet/elasticsearch-python/.venv/lib/python3.11/site-packages/langchain_community/vectorstores/elasticsearch.py:166\u001b[0m, in \u001b[0;36mApproxRetrievalStrategy.query\u001b[0;34m(self, query_vector, query, k, fetch_k, vector_query_field, text_field, filter, similarity)\u001b[0m\n\u001b[1;32m    158\u001b[0m     knn[\u001b[39m\"\u001b[39m\u001b[39mquery_vector_builder\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m {\n\u001b[1;32m    159\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mtext_embedding\u001b[39m\u001b[39m\"\u001b[39m: {\n\u001b[1;32m    160\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mmodel_id\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mquery_model_id,  \u001b[39m# use 'model_id' argument\u001b[39;00m\n\u001b[1;32m    161\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mmodel_text\u001b[39m\u001b[39m\"\u001b[39m: query,  \u001b[39m# use 'query' argument\u001b[39;00m\n\u001b[1;32m    162\u001b[0m         }\n\u001b[1;32m    163\u001b[0m     }\n\u001b[1;32m    165\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    167\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mYou must provide an embedding function or a\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    168\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m query_model_id to perform a similarity search.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    169\u001b[0m     )\n\u001b[1;32m    171\u001b[0m \u001b[39m# If hybrid, add a query to the knn query\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[39m# RRF is used to even the score from the knn query and text query\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \u001b[39m# RRF has two optional parameters: {'rank_constant':int, 'window_size':int}\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[39m# https://www.elastic.co/guide/en/elasticsearch/reference/current/rrf.html\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhybrid:\n",
      "\u001b[0;31mValueError\u001b[0m: You must provide an embedding function or a query_model_id to perform a similarity search."
     ]
    }
   ],
   "source": [
    "docs = db._search( query = {\"match\": {\"House\": \"Gryffindor\"}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.client.indices.refresh(index=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"reuters21578\", 'ModHayes', split=\"train[:1%]\")\n",
    "\n",
    "metadata = []\n",
    "content = []\n",
    "chunk_size = 300\n",
    "chunk_overlap_part = 2\n",
    "\n",
    "for doc in dataset:\n",
    "    content.append(doc[\"text\"])\n",
    "    metadata.append({\n",
    "        \"name\": doc[\"title\"]\n",
    "    })\n",
    "\n",
    "#docs = split_by_chunk(documents=content, chunk=chunk_size, metadata = metadata)\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_size/chunk_overlap_part,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    "    keep_separator=False,\n",
    "    separators = [\"     \", \". \", \" \", \"\"]\n",
    ")\n",
    "\n",
    "docs = text_splitter.create_documents(content, metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.client.ingest.put_pipeline(\n",
    "    id=\"embeddings\",\n",
    "    processors=[\n",
    "        {\n",
    "            \"inference\": {\n",
    "                \"model_id\": model_id,\n",
    "                \"field_map\": {\"_ingest._value.page_content\": \"text_field\"},\n",
    "                \"target_field\": \"vector_query_field\",\n",
    "            }\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "db.client.indices.create(\n",
    "    index=index_name,\n",
    "    mappings={\n",
    "        \"dynamic\": \"true\",\n",
    "        \"properties\": {\n",
    "            \"vector_query_field\": {\n",
    "                \"properties\": {\n",
    "                    \"predicted_value\": {\n",
    "                        \"type\": \"dense_vector\",\n",
    "                        \"dims\": 384,\n",
    "                        \"index\": True,\n",
    "                        \"similarity\": \"cosine\",\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            \"name\" :{\"type\": \"text\"}, \n",
    "        }\n",
    "    },\n",
    "    settings={\"index\": {\"default_pipeline\": \"embeddings\", \"refresh_interval\" : \"1000s\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.from_documents(\n",
    "    docs,\n",
    "    es_cloud_id=ELASTIC_CLOUD_ID,\n",
    "    es_api_key=ELASTIC_API_KEY,\n",
    "    index_name=index_name,\n",
    "    query_field=\"text_field\",\n",
    "    vector_query_field=\"vector_query_field.predicted_value\",\n",
    "    strategy=ElasticsearchStore.ApproxRetrievalStrategy(\n",
    "        query_model_id=model_id\n",
    "    ),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
